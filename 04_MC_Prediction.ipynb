{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_MC_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDbFcMyElI5j19ksxAZ6r6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavoodSZ1993/RL/blob/main/04_MC_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEwBuGms-Xuu",
        "outputId": "1a768a43-9b50-4681-e1a1-fca6de3e546e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Discrete(2), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "env= gym.make('Blackjack-v0')\n",
        "env.action_space, env.action_space.sample()  # two actions: 0: stay, 1: hit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Play Blackjack\n",
        "\n",
        "* Blackjack is a card game where the goal is to obtain cards that sum to as near as possible to 21 without going over.  They're playing against a fixed dealer.\n",
        "\n",
        "* Face cards (Jack, Queen, King) have point value 10.\n",
        "\n",
        "* Aces can either count as 11 or 1, and it's called 'usable' at 11.\n",
        "\n",
        "* This game is placed with an infinite deck (or with replacement).\n",
        "\n",
        "* he game starts with each (player and dealer) having one face up and one face down card. \n",
        "\n",
        "* The player can request additional cards (hit=1) until they decide to stop\n",
        " (stick=0) or exceed 21 (bust).\n",
        "\n",
        "* After the player sticks, the dealer reveals their facedown card, and draws until their sum is 17 or greater.  If the dealer goes bust the player wins.\n",
        "\n",
        "* If neither player nor dealer busts, the outcome (win, lose, draw) is\n",
        " decided by whose sum is closer to 21.  The reward for winning is +1,\n",
        "  drawing is 0, and losing is -1.\n",
        " \n",
        "* The observation of a 3-tuple of: the players current sum,\n",
        " the dealer's one showing card (1-10 where 1 is ace),\n",
        "  and whether or not the player holds a usable ace (0 or 1).\n",
        "  \n",
        "* This environment corresponds to the version of the blackjack problem\n",
        " described in Example 5.1 in Reinforcement Learning: An Introduction\n",
        " by Sutton and Barto (1998).\n"
      ],
      "metadata": {
        "id": "Iq-g4qZUDTFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Observation tuple for Blackjack:\n",
        "1. Sum of players cards (ace counts 11)\n",
        "2. sum of dealers card\n",
        "3. player has useable ace\n",
        "\"\"\"\n",
        "\n",
        "observation_space = env.observation_space.spaces\n",
        "observation_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2ro8qg7BWyg",
        "outputId": "1bf83bf6-b68c-45cd-ca3f-d04647bd9b3b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Discrete(32), Discrete(11), Discrete(2))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resests the state of the environment and returns an initial observation.\n",
        "\n",
        "observation = env.reset()\n",
        "observation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5UCOj9wCaDg",
        "outputId": "c887ea1e-104b-44d1-c65e-1bb7e93a3dd7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 4, False)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = 0\n",
        "observation, reward, done, info = env.step(action)\n",
        "observation, reward, done, info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ivom2sWC3EB",
        "outputId": "05bf65ef-a247-48ca-f0a3-0f5500cec950"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 4, False), -1.0, True, {})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Policy\n",
        "For each observation we need an action:"
      ],
      "metadata": {
        "id": "mXV3C-u9FZEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are invalid states, but we don't care for convenience.\n",
        "state_space_size = (33, 12, 2)\n",
        "\n",
        "policy = np.zeros(state_space_size, dtype=int)"
      ],
      "metadata": {
        "id": "OyO-ZIbrFXRv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def observation_clean(observation):\n",
        "  return (observation[0], observation[1], int(observation[2]))\n",
        "\n",
        "observation = observation_clean(observation)\n",
        "policy[observation]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTMjBJnpGPcf",
        "outputId": "78dcdcf8-e946-4bf0-fc5e-ae60a54b4bf1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo Policy Evaluation\n"
      ],
      "metadata": {
        "id": "CpnCjUhCGu1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(policy, env=env):\n",
        "  steps = []\n",
        "  observation = observation_clean(env.reset())\n",
        "  done = False\n",
        "  steps.append(((None, None) + (observation, 0))) # State, Action, Next State, Reward\n",
        "\n",
        "  while not done:\n",
        "    action = policy[observation]\n",
        "    observation_action = (observation, action)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    observation = observation_clean(observation)\n",
        "    steps.append(observation_action + (observation, int(reward)))\n",
        "\n",
        "  return steps # list of tuples: (s, a, s', R)\n"
      ],
      "metadata": {
        "id": "v9jS1tgZG7NG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_episode(policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ndSgSTIUU4",
        "outputId": "869192bb-4a9c-4a46-ae5e-02725d86ecdf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, None, (16, 6, 0), 0), ((16, 6, 0), 0, (16, 6, 0), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Side Note: Python `reversed` Fucntion:\n",
        "\n",
        "Python reversed() method returns an iterator that accesses the given sequence in the reverse order.\n",
        "\n",
        "#### Code Example:\n",
        "\n",
        "```Python\n",
        "Code: \n",
        "\n",
        "seqTuple = ('g', 'e', 'e', 'k', 's')\n",
        "print(list(reversed(seqTuple)))\n",
        "\n",
        "Output:\n",
        "\n",
        "['s', 'k', 'e', 'e', 'g']\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "SQaPAusRRkEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "\n",
        "N = np.zeros(state_space_size, dtype=int)\n",
        "S = np.zeros(state_space_size)\n",
        "\n",
        "# Every visit monte carlo\n",
        "nb_of_episodes = 100\n",
        "for e in range(nb_of_episodes):\n",
        "  observations_reward = run_episode(policy)\n",
        "  G = 0.\n",
        "  # print (observation_reward)\n",
        "  for o0, a, o, r in reversed(observations_reward):\n",
        "    G = r + gamma * G\n",
        "    N[o] += 1\n",
        "    S[o] +=G\n",
        "    # print(o, r, G)"
      ],
      "metadata": {
        "id": "lR4wiFcsKpXX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observations_reward = run_episode(policy)\n",
        "print(observations_reward)\n",
        "print(list(reversed(observations_reward)))\n",
        "(o0, a, o, r) = list(reversed(observations_reward))[0]\n",
        "print(o0), print(a), print(o), print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YAC0EhaP1H1",
        "outputId": "b3048e79-a1f3-4280-822f-375bd70ed272"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(None, None, (20, 7, 0), 0), ((20, 7, 0), 0, (20, 7, 0), 0)]\n",
            "[((20, 7, 0), 0, (20, 7, 0), 0), (None, None, (20, 7, 0), 0)]\n",
            "(20, 7, 0)\n",
            "0\n",
            "(20, 7, 0)\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}